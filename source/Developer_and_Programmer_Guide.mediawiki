= Introduction =
The ''Stream Oriented GE Kurento'' is a multimedia platform helping developers to add multimedia capabilities to their applications. The core element is the ''Kurento Media Server'' (or "KMS", for short), a  [http://gstreamer.freedesktop.org/ ''Gstreamer''] based multimedia engine that provides the following features: 

* Networked streaming protocols, including ''HTTP'' working as client and server, ''RTP'' and ''WebRTC''.
* Media transcodification between any of the codecs currently supported by Gstreamer.
* Generic support for computational vision and augmented reality filters.
* Media storage supporting writing operations for ''WebM'' and ''MP4'' and reading operations for any of ''Gstreamer's'' muxers.

[http://www.java.com/ ''Java''] and [http://www.w3.org/standards/webdesign/script ''Javascript''] SDKs are available for developers, to incorporate the above features in their applications.

== About this guide ==
This guide, as the ''Stream Oriented GE Kurento'' itself, is under very active development. Many features are constantly evolving and are not completely documented yet. You can contribute to complete this guide and also to Kurento effort by joining its community.

= User Guide = 
The ''Stream Oriented GE Kurento'' offers APIs devoted to programmers, not to final users, so this section does not apply.

= Programmer Guide = 
== Things you need to know before start programing ==

* The ''Stream Oriented GE Kurento'' software is released under [http://www.gnu.org/licenses/lgpl-2.1.html ''LGPL'' version 2.1] license. This is quite a convenient license for programmers, but it is still recommended you check if it actually fits your application needs.

* [http://maven.apache.org/ ''Maven''] is used as dependency management tool for ''Java'' SDKs. Most likely [http://www.gradle.org/ ''Gradle''] can also be used, but we still haven't tested it. If you don't use any dependency management you can still download the [https://forge.fi-ware.eu/frs/download.php/819/kmf-api.jar ''KMF API Bundle''] and incorporate manually all dependencies to your application, but this is not recommended.

* [http://spring.io/ ''Spring framework''] is extensively used for lifecycle management of ''Java'' components. Developers are not required to develop ''Spring '' applications when using the ''Stream Oriented GE Kurento - Content API'' in ''Java EE'' environments, but they'll have to when developing applications with ''Media API''.

== Quick start ==
This section is intended to provide the very basic steps required to integrate the ''Stream Oriented GE Kurento's'' framework into applications.
=== Basic Setup === 
* '''''Install and configure Kurento Media Server (KMS)''''': This piece of software is the actual engine providing media processing and delivery.

* '''''Install and configure JBoss 7 Application Server (KAS)''''': This is a ''Java EE'' container that hosts the server side of applications. Other ''Java'' enterprise servers can be used, although no support from ''Kurento'' will be provided. This server will also be called ''Kurento Application Server'' (''KAS'') through the document.
The [[StreamOriented_-_Installation_and_Administration_Guide(3.3)|StreamOriented - Installation and Administration Guide]] provides detailed information on installation and setup of above components.

=== Create your first application ===
==== Server side of your first application ====
The ''Stream Oriented GE Kurento'' server SDK is a ''Java'' library known as ''Kurento Media Framework'' (''KMF''). The following steps are required to create a ''Kurento'' based application:

<ol>
<li>Create a ''Maven'' web project with your favourite IDE. You can use the following <code>pom.xml</code> template. Please notice that '''Java 1.7''' is required to compile KMF-based Java projects.
<pre>
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">

    <modelVersion>4.0.0</modelVersion>
    <groupId>my.organization</groupId>
    <artifactId>my-kurento-demo</artifactId>
    <version>1.0.0</version>
    <packaging>war</packaging>

    <properties>
        <project.build.sourceEncoding>UTF-8 </project.build.sourceEncoding>
        <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>
        <maven.compiler.source>1.7</maven.compiler.source>
        <maven.compiler.target>1.7</maven.compiler.target>
    </properties>

</project>
</pre>
</li>
<li>You can add ''KMF'' dependencies to the <code>pom.xml</code> file as follows:
<pre>
<dependencies>
    ...
    <dependency>
        <groupId>com.kurento.kmf</groupId>
        <artifactId>kmf-content-api</artifactId>
        <version>4.2.2</version>
    </dependency>
    ...
</dependencies>
</pre>

NOTE: We are in active development. Be sure that you have the latest Kurento version in your POM. You can find it in the [http://search.maven.org/#search%7Cga%7C1%7Cg%3A%22com.kurento%22 Maven Central] section of kurento.org.

</li>
<li>''KMF'' requires to be deployed in an Application Server with a container supporting the version 3.0 of the Servlet specification. Therefore, ensure that this version is established in <code>WEB-INF/web.xml<code>:
<pre>
<web-app xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xmlns="http://java.sun.com/xml/ns/javaee" xmlns:web="http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd"
	xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd"
	version="3.0">
</web-app>
</pre>
</li>

<li>Create a properties file named <code>kurento.properties</code> including the following configuration keys:
<pre>
# Put here the IP address where the KMS process is executing
# If you launched KMS in the same hosts where you are executing KAS, let it as 127.0.0.1
thriftInterfaceConfiguration.serverAddress=127.0.0.1

# Put here the port where KMS management daemon is bound
# If you did not modify KMS default configuration, let it as 9090
thriftInterfaceConfiguration.serverPort=9090

# Put here the IP address where KAS management handler must listen
# If you launched KMS int the same host where you are executing KAS, let it as 127.0.0.1
mediaApiConfiguration.handlerAddress=127.0.0.1

# Port where KAS management daemon will bind
# Your can choose the port you want. By default we assume 9100.
mediaApiConfiguration.handlerPort=9100
</pre>
''Kurento'' framework will search this file in the following locations (in the specified order): 
<ul>
<li>''JBoss'' configuration folder defined by property: <code>${jboss.server.config.dir}</code>
 </li>
<li>Directory specified by java option ''kurento.properties.dir'': <code>-Dkurento.properties.dir=/home/user/kurento</code>
  </li>
<li>''WEB-INF'' directory of ''WAR'' archive</li>
</ul>
</li>
<li>Create a ''Java'' Class that extends <code>HttpPlayerHandler</code>, and add the annotation <code>@PlayerService</code>. You'll have to implement the method <code>onContentRequest()</code> to set the media resource to be played.
<pre>
import com.kurento.kmf.content.HttpPlayerHandler;
import com.kurento.kmf.content.HttpPlayerService;
import com.kurento.kmf.content.HttpPlayerSession;

@HttpPlayerService(path = "/playerService", useControlProtocol=false)
public class MyService extends HttpPlayerHandler {

	@Override
	public void onContentRequest(HttpPlayerSession session) throws Exception {
		session.start("file:///path/to/myvideo.webm");
	}
}
</pre>
</li>
<li>Place a ''WebM'' video so that the KMS process can reach it at whatever path you specified in <code>/path/to/myvideo.webm</code>. This video will be the one read by the player element. You can replace the <code>file:///</code> type URL by another one where a WebM file can be found, such as <code>http://media.w3.org/2010/05/sintel/trailer.webm</code></li>
<li>Package the project into a .war file.</li>
<li>Deploy your project into ''JBoss 7'' server installed during the basic setup and start it.
<pre>
sudo cp mykurento.war $JBOSS_HOME/standalone/deployments
sudo /etc/init.d/jboss7 start
</pre>
</li>
</ol>

==== Client side of your first application ====

The ''Stream Oriented GE Kurento'' is designed to work with plain ''HTML5'' code. For testing your application, you just have to include a <code><video></code> tag linked to the ''service URL'' defined above. To do it, for example, create an HTML file in your local machine containing the code shown below and open it with your browser.

<pre>
<video>
    <source src="http://myServer/myApp/playerService" type ="video/webm"/>
</video>
</pre>

You can read also section [[Programming with the Stream Oriented GE HTML5 SDK]] to find out more sophisticated ways to access media resources.

=== Next steps ===
* Read [[#Basic streaming concepts]] in order to understand how ''Stream Oriented GE Kurento'' features can help you to build multimedia applications.
* Review [[#Programming with the Stream Oriented GE Java EE Content API]] for a detailed reference on content services.
* Go to [[#Programming with the Stream Oriented GE Java Media API]] for a detailed explanation about how to achieve full control of ''Kurento Media Server''.
* Review [[#Programming with the Stream Oriented GE HTML5 SDK]] for a detailed reference of capabilities available in browsers.

== Basic streaming concepts ==
There are several streaming concepts that might be of interest, in order to know the precise behaviour that can be expected when adding multimedia resources to applications.

Any streaming protocol requires two main components: a ''control function'' to manage connection setup, and a ''media function'' that actually provides media process & transfer capabilities. For true streaming protocols, like ''RTP'', ''RTSP'', ''RTMP'' or ''WebRTC'' there is a clear differentiation between both functions. Actually ''RTP'' is the media function of the ''RTSP'' protocol. ''RTP'' can also be used in conjunction with other control protocols like ''SIP'' or ''XMPP''. ''WebRTC'' is a media function like ''RTP'' and it also requires a control protocol that negotiates connection setup.

Streaming over ''HTTP'' (a.k.a.  ''HTML5 streaming'') is somehow special because ''HTTP'' is a not protocol designed for media transfer. ''HTML5 streaming'' sessions start with the browser sending a GET request to the server. In this step both browser and server play the ''control function'' role. The server then maps the URL to the actual resource, encapsulates its content in the response, and sends it back to the <code><video></code> component, just like any download operation. Now browser and server switch to the ''media function''. There isn't a clear differentiation between control and media functions that are played sequentially by the same element in both sides. Apart form this function mixup, many people will argue that ''HTTP'' is not really a streaming protocol, since there is no relation at all between media transfer pace an playing pace, i.e. the network transfer rate is not limited by the media consumption rate and you might find situations where the whole content of a 1 hour video is already downloaded when still playing the first minute. 

There is quite an important and somehow confusing concept related to the capability to jump to a time position within a stream. This operation is normally called ''SEEK'' and streams that supports it are called ''seekable''. Those not supporting ''SEEK'' operation are called ''live'' or ''non-seekable''. There are two conditions a stream must meet in order to be ''seekable''. First, the control protocol must provide a ''SEEK'' command and second, the media resource must be completely available before the stream starts transmission. The reason for the second condition, is because seeks must specify somehow the file position where the stream must jump, and that requires to know in advance the size or length of the media resource. Hence the whole resource must be available in advance. Streaming protocols like ''RTSP'' and ''HTTP'' use header <code>Range</code> as a mean to build seek command. When the <code><video></code> component in an ''HTML5'' application request a seek operation, the browser sends a new GET request with the appropriate <code>Range</code> header. But this is only available if the server provided the resource size in advance in the first request (the one that initiated the stream). If resource size is not available at start time, the video component does not show any kind of progress bar, switching into ''live'' mode. ''Stream Oriented GE Kurento'' is currently supporting only ''live'' mode, independently of whether the media resource is available in advance or not.

When designing streaming services it is also very important to determine the type of service that is being offered. There are two main classifications for streaming services: ''Video on demand'' (''VoD'') and ''Broadcast''. Main difference between these two services is the streaming time scale. In ''Broadcast'' mode any new client connecting to the streaming service assumes the time scale defined by the source, and this time scale is shared among all connected clients. In ''VoD'' service a new time scale is built for each client. The client not only selects resource, but also the time of origin. When many ''VoD'' clients access the same resource, each one has its own time scale, and this time scale is reset if the client breaks the connection. ''Stream Oriented GE Kurento'' is currently supporting Broadcast services, but in future versions it will also support true ''VoD'' mode.

== Stream Oriented GE Kurento API architecture ==

The ''Stream Oriented GE Kurento'' is a multimedia platform that provides streaming capabilities in a very flexible way.  As described in the [[FIWARE.ArchitectureDescription.Data.StreamOriented | Architecture Description]], ''Kurento'' is a modular system where a set of basic functional blocks, called ''MediaElements'', that live in containers, called ''MediaPipelines'', are connected together to build multimedia services. There are three main ''MediaElement'' families:
* '''''Endpoints''''': Endpoints provide transfer capabilities, allowing bidirectional communication channels with external systems. Supported protocols include muxers, like ''WebM'' or ''MP4'' for file operations and following streaming protocols: ''HTTP'', ''RTP'' and ''WebRTC''.
* '''Filters''': Filters are responsible of media processing, including transcodification, computer vision, augmented reality, etc.
* '''Mixers''': Mixers combines the stream from endpoints. They are also kwnon as ''Hub''. The main mixers types are ''Dispatcher'' and ''Composite''.

The ''Stream Oriented GE Kurento'' consists of two main software components: ''Kurento Media Server'' (''KMS'') and ''Kurento Media Framework'' (''KMF''):
* '''''KMS''''': ''Kurento Media Server'' is a stand-alone server responsible of the media process and delivery. It is the component that hosts ''Endpoints'' and ''Filters''. 
* '''''KMF''''': ''Kurento Media Framework'' is the SDK that enables applications to control ''KMS'' features and publish multimedia services. ''KMF'' provides the following APIs:
** ''<u>Content API</u>'': High-level middleware layer of services intended to simplify communications with clients. It also offers Open API to clients.
** ''<u>Media API</u>'': Low-level API that provides full control of ''KMS'' elements. It is normally used in conjunction with ''Content API''.
** ''<u>HTML5 SDK</u>'': Javascript SDK intended to provide better control of media playing in web applications. It uses Open API (based on JSON-RPC over http and websockets) to communicate with Content API in the server.

== Programming with the Stream Oriented GE Java EE Content API ==

The ''Content API'' SDK is intended to simplify setup and management of multimedia connections between ''KMS'' and web applications. Built on top of the ''Java EE Servlet'' API, implements a ''REST''-like interface based on JSON-RPC that controls following multimedia services:

* '''''HTTP services''''': Enables download and upload of multimedia contents.
* '''''RTP services''''': Allows the setup of bidirectional RTP connections.
* '''''WebRTC services''''': Controls ''WebRTC'' connections with browsers and mobile devices implementing the ''WebRTC'' stack.

It is important to notice that the ''Content API'' is just a ''KMS'' control interface and does not handles media directly.

=== Content services ===

Applications offering multimedia services have to setup and manage ''KMS'' ''Endpoints''. The ''Endpoints'' are heterogeneous and their operation depends on the underlying streaming protocol. This is the reason why the ''Content API'' defines the concept of ''content service'', as a mechanism to provide a simple and homogeneous interface, for the creation and management of multimedia connections.

A ''content service'' consists of a standard ''Java bean'' implementing the ''service handler'' interface. ''Service handlers'' are identified because they are annotated as follows:

<ul>
<li><code>@HttPlayerService</code>: Declares a player service intended to deliver content to ''HTML5'' <code><video></code> elements. The ''service handler'' must extend class <code>HttpPlayerHandler</code>.
  <pre>
@HttpPlayerService(path = "/myPlayerService")
public class MyService extends HttpPlayerHandler{
    …
}
</pre>
</li>
<li><code>@HttpRecorderService</code>: Allows the application to publish a recorder service, enabling media injection into ''KMS'' through the ''HTTP file upload'' protocol. The recorder ''service handler'' must extend class <code>HttpRecorderHandler</code>.
  <pre>
@HttpRecorderService(path = "/myRecorderService")
public class MyService extends HttpRecorderHandler{
    …
}
</pre>
</li>
<li><code>@RtpContentService</code>: Defines a bidirectional ''RTP'' connection. The ''service handler'' must extend class <code>RtpContentHandler</code>.
  <pre>
@RtpContentService(path = "/myRtpService")
public class MyService extends RtpContentHandler{
    …
}
</pre>
</li>
<li><code>@WebRtcContentService</code>: Intended for bidirectional WebRTC connections. Its ''service handler'' must extend class <code>WebRtcContentHandler</code>
  <pre>
@WebRtcContentService(path = "/myWebRtcService")
public class MyService extends WebRtcContentHandler{
    …
}
</pre>
</li>
</ul>

When application starts, the ''Content API'' framework searches for ''content service'' annotations, instantiating a ''service entry point'' for each ''service handler'' found. Internally, a ''service entry point'' is basically an ''HTTP servlet'', mapped to a ''service URL'' where clients can send HTTP requests with control commands. Developers do not have to care about servlet configuration or initialisation, as the ''Content API'' takes care of this operations. The ''service URL'' has the format specified below:

<pre>
http://myserver/myApp/myServiceName
</pre>

where
* <u>''myserver''</u> : is the IP address or hostname of the ''Kurento Application Server''.
* <u>''myApp''</u>: is the application context, namely the WAR archive name if not otherwise specified.
* <u>''myServiceName''</u> : is the value given to the <code>path</code> attribute of service annotation.

As a summary, in order to create a ''content service'' the application must implement a ''service handler'', which is a ''Java bean'' with a common interface. The ''Content API'' instantiates an ''HTTP servlet'' for each ''service handler'' found. This servlet is known as the ''service entry point'', and can be reached at the ''service URL''. Service operation and management is independent of the underlying  ''KMS'' ''Endpoint'' type. It is important to understand that developers do not need to care about instantiation of ''service entry points' '' servlets and that these are used just for control purposes and not for media delivery.  

==== HTTP Player Service ====

The ''HTTP Player service'' instantiates a download service intended for ''HTML5 streaming''. Method <code>onContentRequest()</code> is called every time the ''service entry point'' receives a GET request from a client using Open API (directly or with HTML5 SDK).

<pre>
import com.kurento.kmf.content.HttpPlayerHandler;
import com.kurento.kmf.content.HttpPlayerService;
import com.kurento.kmf.content.HttpPlayerSession;

@HttpPlayerService(path = "/myPlayerService")
public class MyService extends HttpPlayerHandler{

	@Override
	public void onContentRequest(HttpPlayerSession session) throws Exception {
		session.start("file:///path/to/myvideo");
	}
}
</pre>
''KMS'' instantiates ''HTTP Endpoints'' on behalf of this service every time a new request arrives. ''HTTP Endpoints'' transform content on the fly to ''WebM'' (by default) or ''MP4'' before encapsulation and delivery, allowing source files to have any format supported by ''Gstreamer''.

''HTML5'' browsers can access the content by adding the ''service URL'' as source of the tag <code><video></code>.
<pre>
<video>
    <source src="http://myServer/myApp/myPlayerService" type ="video/webm"/>
</video>
</pre>
Current version of the ''Content API'' only supports ''live'' mode independently of the nature of the media archive. Future versions will support pseudo-streaming for media resources whose file size can be known before transmission is started.
* '''''Known issue''''': A bad behavior with Chrome has been observed, when the ''service URL'' is placed in the address bar of the browser. This is due to a reconnection Chrome performs when it detects MIME of type video or audio. Root cause for this problem relates to the fact that ''Kurento'' provides ''VoD'' services based on top of a broadcast service, and time scale initialisation is not performed on reconnection. Future versions will provide true ''VoD'' capabilities, solving this problem.

==== HTTP Recorder Service ====

''HTTP recorder service'' allows applications to inject contents into ''KMS'', through the standard file upload protocol. Method <code>onContentRequest()</code> will be called for each <code>multipart/form</code> ''POST'' request received in the ''service entry point''. The receiver ''HTTP Endpoint'' will search for the first ''content part'' with a supported multimedia format, and will feed the media resource specified by the handler (<code>file:///myfile.webm</code>).  ''Recorder service'' accepts from a client any multimedia format supported by ''Gstreamer'', but transforms content to ''WebM'' or ''MP4'' before storing it.

<pre>
import com.kurento.kmf.content.HttpRecorderHandler;
import com.kurento.kmf.content.HttpRecorderService;
import com.kurento.kmf.content.HttpRecorderSession;

@HttpRecorderService(path = "/myRecorderService")
public class MyRecorderService extends HttpRecorderHandler {

	@Override
	public void onContentRequest(HttpRecorderSession contentSession)
			throws Exception {
		contentSession.start("file:///myfile.webm");
	}
}
</pre> 

Browsers can access this service through HTML forms, addressed to the ''service URL'', that include inputs of type file. If more than one file is present the request will accept only first one found.
<pre>
<form action=”http://myServer/myApp/myRecorderService”>
	File: <input type="file" name="data" >
</form>
</pre>

==== RTP & WebRTC Service ====

''RTP'' and ''WebRTC'' requires a negotiation process where each side sends its connection details and supported formats encoded in a ''SDP'' (''Session Description Protocol'') packet. ''RTP'' and ''WebRTC'' services hide negotiation complexity, offering applications the same interface used for the well-known ''HTTP'' services. Method <code>onContentRequest()</code> is called each time a ''POST'' request with a connection offer is received by the ''service entry point''.

<pre>
import com.kurento.kmf.content.WebRtcContentHandler;
import com.kurento.kmf.content.WebRtcContentService;
import com.kurento.kmf.content.WebRtcContentSession;
import com.kurento.kmf.media.MediaPipeline;
import com.kurento.kmf.media.MediaPipelineFactory;
import com.kurento.kmf.media.PlayerEndpoint;
import com.kurento.kmf.media.RecorderEndpoint;

@WebRtcContentService(path = "/myWebRtcService")
public class MyWebRtpService extends WebRtcContentHandler {

    @Override
    public void onContentRequest(WebRtcContentSession contentSession)throws Exception {
        contentSession.start("file:///fileToSend.webm","file:///fileToRecord.webm");
    }
}
</pre>

''RTP'' and ''WebRTC'' are bidirectional protocols that can send and receive at the same time. For that reason, <code>start</code> method requires both ''source'' and ''sink'' elements.

In the previous example, the received media from the client will be recorded into ''fileToRecord.webm'' and the media to deliver to the client is read from ''fileToSend.webm''. The start method it not limited to read from files and write to files. More complex media pipelines can be created with ''Media API'' as we will see in the following sections of this document.

The client starting the communication with the server specifies some constraints for media direction in the negotiating phase. The handler can access to this constraints individually for video and audio streams with methods <code>WebRtcContentSession.getVideoConstraints()</code> and <code>WebRtcContentSession.getAudioConstraints()</code>. These methods return one of the following values:
* '''''SENDONLY''''': ''KMS'' receives media from the client and does not deliver to it.
* '''''RECVONLY''''': ''KMS'' delivers media to the client and does not receive from it.
* '''''SENDRECV''''': ''KMS'' sends and receives media at the same time.
* '''''INACTIVE''''': There is no media transfer in any direction, independently of any player or recorded connected. This is useful when only video or audio can be transmitted. 

Played file can take any format supported by ''Gstreamer'', and will be translated to a format negotiated with the remote peer. Stored file will be converted to ''WebM'' or ''MP4'' from the format negotiated with remote peer.


=== Content Session & Media lifecycle ===

The ''content session'' is the mechanism offered by the ''Content API'' to manage multimedia transactions. Its state depends on media events detected in the ''Endpoint'', control events detected in the ''service entry point'' and application commands. 

The ''content session'' is created when a request is received in the ''service entry point''. Method <code>onContentRequest()</code> is called in the ''service handler'', so the application can accept or reject requests. Rejected requests must provide the message and the ''HTTP'' error code that will be returned to browser.
<pre>
@Override
public void onContentRequest(WebRtcContentSession contentSession) throws Exception {
	contentSession.terminate(404, "Content not found");
}
</pre>

When the ''service handler'' wants to accept a request, it must provide the source and sink media resources that will be connected to the ''Endpoint''. Method <code>start()</code> is called for this purpose.
<pre>
@Override
public void onContentRequest(WebRtcContentSession contentSession) throws Exception {
	contentSession.start("file:///fileToSend.webm","file:///fileToRecord.webm");
} 
</pre>

The ''Endpoint'' informs applications when a media transfer starts by calling the optional method <code>onContentStarted()</code>.

<pre>
@Override
public void onContentStarted(WebRtcContentSession contentSession) Exception {
	// Execute specific application logic when content (media) starts being served to the client
}
</pre>

Optional method <code>onSessionTerminated()</code> is called when ''Endpoint'' completes media transfer. The ''content session'' termination code is provided in this call.

<pre>
@Override
public void onSessionTerminated(WebRtcContentSession contentSession, int code, String reason) throws Exception {
	// Execute specific application logic when content session terminates
}
</pre>

The ''content session'' is terminated automatically if the ''Endpoint'' experiences an unrecoverable error not caused by a direct application command. Events like client disconnection, file system access fail, etc. are the main error cause. Any of these exceptions can be handled on <code>onUncaughtException()</code>. 

<pre>
@Override
public void onUncaughtException(HttpPlayerSession contentSession, Throwable exception) throws Exception {
	// Execute specific application logic if there is an unrecoverable
        // error on the media infrastructure. Session is destroyed after 
        // executing this code
}
</pre>

If exceptions are not handled, they will be propagated and the method <code>onSessionError()</code> will be called with the error code and description.

<pre>
@Override
public void onSessionError(WebRtcContentSession contentSession, int code, String description) throws Exception {
	// Execute specific application logic if there is an unrecoverable
        // error on the media infrastructure. Session is destroyed after 
        // executing this code
}
</pre>

The ''content session'' is able to store and manage application attributes through its lifecycle, in a similar way as <code>HttpSession</code> does. Method <code>setAttribute()</code> stores an object of any class that can later be retrieved with method <code>getAttribute()</code> or deleted with method <code>removeAttribute()</code>.  

<pre>
@Override
public void onContentRequest(WebRtcContentSession contentSession) throws Exception {
	contentSession.setAttribute("source", "source.avi");
	contentSession.setAttribute("sink", "sink.webm");
	//...
}
	
@Override
public void onContentStarted(WebRtcContentSession contentSession) throws Exception {
	String source = (String) contentSession.getAttribute("source");
	String sink = (String) contentSession.getAttribute("sink");
	log.info("Start playing: " + source);
	log.info("Start recording:" + sink);
}

</pre>

One important feature of the ''content session'', is its capability to share real time information with clients through a bidirectional channel. In order to interchange messages with a client, the [http://forge.fi-ware.eu/plugins/mediawiki/wiki/fiware/index.php/StreamOriented_Open_API_Specification_(PRELIMINARY)''Open API''] has to be used. In the web browsers is recommended connect to the server with the HTML5 SDK, because it fully implements OpenAPI. 

The OpenAPI is implemented following a signalling protocol based on ''JSON-RPC 2.0''. Messages can be interchanged between the ''service handler'' and the client, while the ''content session'' is active. Method <code>publishEvent()</code> can be used from the handler to sent events to the client. This capability is quite useful combined with computer vision filters, as it allows sending events to clients coming from video content analysis (e.g. plate recognised, QR code detected, face detected, etc.).

<pre>
@Override
public void onContentStarted(WebRtcContentSession contentSession) throws Exception {
	ContentEvent event = new ContentEvent();
	event.setType("tittle");
	event.setData("My Video");
	contentSession.publishEvent(event);
}
</pre>

Clients can also send messages to the ''content session'' through this channel. Client messages are called commands, and are received on handler method <code>onContentCommand()</code>

<pre>
@Override
public ContentCommandResult onContentCommand( WebRtcContentSession contentSession, ContentCommand contentCommand) throws Exception {
	String data = contentCommand.getData();
	String type = contentCommand.getType();
		
	//Process command...

	return new ContentCommandResult("OK");
}
</pre>

See the [http://forge.fi-ware.eu/plugins/mediawiki/wiki/fiware/index.php/StreamOriented_Open_API_Specification_(PRELIMINARY)''Open API''] specification for a detailed reference of available commands and events that can be exchanged between ''service handlers'' and clients.

=== Content identification ===

Content identification can be understood as the process of mapping media resources to URLs. The rules and algorithms used are quite variable and application dependant, although there are several possible strategies. A very common one is the direct mapping between the URL path and a file system path, which actually is the strategy used by the most HTTP servers  to map static resources. Other alternative is to assign a content ID to each media resource. This content ID can be placed in the URL's path info or in the query string, as parameter. The server searches for the content ID in the appropriate place and looks up a mapping table. 

The ''content session'' provides method <code>getContentId()</code> that returns the path info of requested URL’s, assuming the content ID is placed there, as shown below:

; Content URL <nowiki>: http://myserver/myApp/myServicePath/{contentId}</nowiki>
: ''myserver'': IP address or name of ''Kurento Application Server''
: ''myApp'': Application name. Normally is the WAR archive name
: ''myServicePath'': Value assigned to <code>path</code> attribute of service annotation
: ''{contentId}'': URL's path info. Everything left between service name and the URL's query string. 

<pre>
@Override
public void onContentRequest(HttpPlayerSession contentSession) throws Exception {
	String contentId = contentSession.getContentId();	
	contentSession.start("file:///path/to/myrepo/" + contentId);
}
</pre>

If a different content ID strategy, based in a query string parameter or the like, is used, the application can directly access the requested URL through method <code>getHttpServletRequest()</code>
<pre>
@Override
public void onContentRequest(HttpPlayerSession contentSession) throws Exception {
	String contentId;
	HttpServletRequest request = contentSession.getHttpServletRequest();
	request.getContextPath();
	request.getQueryString();
	
	// build content ID from URL 
		
	contentSession.start("file:///path/to/myrepo/" +contentId);
}
</pre>

Notice you'll have to add the Servlet API dependency to the <code>pom.xml</code> before being able to import <code>HttpServletRequest</code> in your code.

<pre>
<dependency>
	<groupId>javax.servlet</groupId>
	<artifactId>javax.servlet-api</artifactId>
	<version>3.0.1</version>
	<scope>provided</scope>
</dependency>
</pre>

=== Media resource management ===

The ''Content API'' does not require an explicit resource management unless the application directly builds ''KMS MediaElements''. Lifecycle of created ''MediaElements'' is not managed anymore by the ''content session'', so the application must care about how and when resources are released.
In order to facilitate resource management, the ''content session'' provides a mechanism to attach ''MediaElements'' to the session lifecycle. Method <code>releaseOnTerminate()</code> can be used for this purpose.

<pre>
MediaPipelineFactory mpf = contentSession.getMediaPipelineFactory();
MediaPipeline mp = mpf.create();
		
PlayerEndpoint player = mp.createPlayerEndpoint("file:///path/to/myplayed.avi");
contentSession.releaseOnTerminate(player);

HttpGetEndpoint httpEndpoint = mp.newHttpGetEndpoint().terminateOnEOS().build();
player.connect(httpEndpoint);
contentSession.start(httpEndpoint)
</pre>

Single elements can be attached to a session lifecycle, but also the whole ''MediaPipeline'', depending on application needs.

<pre>
MediaPipelineFactory mpf = contentSession.getMediaPipelineFactory();
MediaPipeline mp = mpf.create();
contentSession.releaseOnTerminate(mp);
</pre>

''MediaElements'' not attached to the ''content session'' will remain active until an explicit release is performed.

<pre>
@Override
public void onContentRequest(WebRtcContentSession contentSession) throws Exception {
				
	MediaPipelineFactory mpf = contentSession.getMediaPipelineFactory();
	MediaPipeline mp = mpf.create();
	
	PlayerEndpoint player = mp.newPlayerEndpoint("file:///d").build();

	contentSession.start(player);
}
	
@Override
public void onSessionTerminated(WebRtcContentSession contentSession, int code, String reason) throws Exception {
	player.release();
}
</pre>

=== Content Repository ===

The Stream Oriented GE Java Content API provides a built-in '''content repository''' to store media streams (video and audio files). The elements stored in the repository (called ''repository items'') can be accessed using the method ''start'' of the ''content session'' provided by the Java Content API.

The list of features implemented by the ''content repository'' are:

* Create repository items
* Set metadata in the repository items (key-value attributes)
* Find repository items (by its identifier, attribute value or regular expressions)
* Remove repository items

Let see a couple of examples to illustrate the way of working of the ''content repository''. First, the following  example shows how to use the ''content repository'' to store the stream from an ''HttpRecorderEndpoint'':

<pre>
@HttpRecorderService(path = "/recorderRepository")
public class RecorderRepository extends HttpRecorderHandler {

	@Override
	public void onContentRequest(HttpRecorderSession contentSession)
			throws Exception {
		final String itemId = "itemTunnel";
		Repository repository = contentSession.getRepository();
		RepositoryItem repositoryItem;
		try {
			repositoryItem = repository.findRepositoryItemById(itemId);
			getLogger().info("Deleting existing repository '{}'", itemId);
			repository.remove(repositoryItem);
		} catch (NoSuchElementException e) {
			getLogger().info("Repository item '{}' does not previously exist",
					itemId);
		}
		repositoryItem = contentSession.getRepository().createRepositoryItem(
				itemId);
		contentSession.start("itemTunnel");
	}

}
</pre>

This other example shows how to implement an ''HttpPlayerHandler'' to play a ''repository item'' identified by the ''contentId'' parameter:

<pre>
@HttpPlayerService(path = "/playerRepository/*")
public class PlayerRepository extends HttpPlayerHandler {

	@Override
	public void onContentRequest(HttpPlayerSession contentSession)
			throws Exception {
		String contentId = contentSession.getContentId();
		RepositoryItem repositoryItem = contentSession.getRepository()
				.findRepositoryItemById(contentId);
		if (repositoryItem == null) {
			String message = "Repository item " + contentId + " does no exist";
			getLogger().warn(message);
			contentSession.terminate(404, message);
		} else {
			contentSession.start(repositoryItem);
		}
	}

}
</pre>


== Programming with the Stream Oriented GE Java Media API ==

''Kurento Media API'' is a low level ''Java'' SDK providing full control of ''Kurento Media Server''. It is intended to be used at server side, in conjunction with ''Kurento Content API'', although it can also be used on its own and even within standard ''Java projects'', outside ''Kurento Application Server''.

Following dependency has to be added to <code>pom.xml</code> in order to use ''Kurento Media API'' 

<pre>
<dependencies>
…
    <dependency>
        <groupId>com.kurento.kmf</groupId>
        <artifactId>kmf-media-api</artifactId>
        <version>4.2.2</version>
    </dependency>
…
</dependencies>
</pre>

=== MediaPipeline ===

The <code>MediaPipelineFactory</code> is the API entry point. It can be obtained from the ''content session'' when used in conjunction with the ''Content API ''.

<pre>
   @Override
    public void onContentRequest(HttpPlayerSession contentSession) throws Exception {
        MediaPipelineFactory mpf = contentSession.getMediaPipelineFactory();
    }
</pre>

In order to use the ''Media API'' in stand-alone mode the application must setup a [http://spring.io/ Spring framework] context.

<pre>
public static void main(String[] args) {
    ApplicationContext context = new AnnotationConfigApplicationContext("classpath:kmf-media-config.xml");
    MediaPipelineFactory mpf = context.getBean(MediaPipelineFactory.class);
}
</pre>

The Spring configuration file (<code>kmf-media-config.xml</code> in example above) must contain directive <code><context:component-scan base-package="com.kurento.kmf.media" /></code>, so ''Media API'' components can be found. Optionally a bean of class <code>com.kurento.kmf.media.MediaApiConfiguration</code> can be added with custom configurations.
 
<pre>
<beans xmlns=http://www.springframework.org/schema/beans 
            xmlns:xsi=http://www.w3.org/2001/XMLSchema-instance 
            xmlns:context=http://www.springframework.org/schema/context
    xsi:schemaLocation="http://www.springframework.org/schema/beans
           http://www.springframework.org/schema/beans/spring-beans-3.0.xsd
           http://www.springframework.org/schema/context
           http://www.springframework.org/schema/context/spring-context-3.0.xsd">

    <context:annotation-config />
    <context:component-scan base-package="com.kurento.kmf.media" />

    <bean id="mediaApiConfiguration" class="com.kurento.kmf.media.MediaApiConfiguration">
        <property name="serverAddress" value="127.0.0.1" />
        <property name="serverPort" value="9090" />
        <property name="handlerAddress" value="127.0.0.1" />
        <property name="handlerPort" value="9191" />
    </bean>
</beans>
</pre>

The <code>MediaPipelineFactory</code> can now be injected with any of the mechanism provided by Spring.

<pre>
public class MyApplication {

	@Autowired
	MediaPipelineFactory mpf;
	
	// Application code
}
</pre>

A <code>MediaPipeline</code> object is required to build media services. Method <code>create()</code> can be used in the <code>MediaPipelineFactory</code> for this purpose. 

<pre>
public void init() {
	MediaPipeline mp = mpf.create ();
	
	// Other initializations
}
</pre>

''MediaPipelines'' are the containers where ''KMS MediaElements'' live. ''MediaElements'' within a pipeline can be connected to build services, but they are isolated from the rest of the system. This has to be taken into account when programming applications.

As introduced before, currently there are two kinds of ''MediaElements'', namely ''Endpoints'' and ''Filters''

=== Endpoints ===

''KMS MediaElements'' are created through specific builders, allowing a flexible initialization. Mandatory parameters must be provided in the builder constructor, like the URL in the <code>PlayerEndpoint</code>. Optional parameters are set to defaults unless the application overrides their values.

<pre>
public void createMediaElements() {
	MediaPipeline mp = mpf.create();
	HttpGetEndpoint httpEndpoint = mp.newHttpEndpoint()
		.withDisconnectionTimeout(1000).withGarbagePeriod(100)
		.withMediaProfile(MediaProfileSpecType.WEBM).build();

	PlayerEndpoint player = mp.newPlayerEndpoint("file:///myfile.avi")
		.build();

	RecorderEndpoint recorder = mp.newRecorderEndpoint("file:///myfile.mp4")
		.withMediaProfile(MediaProfileSpecType.MP4)
		.build();
		
	RtpEndpoint rtp = mp.newRtpEndpoint()
		.build();
		
	WebRtcEndpoint webrtc = mp.newWebRtcEndpoint()
		.build();
		
	ZBarFilter zbar = mp.newZBarFilter().build();
		
	// Do something with media elements
}
</pre>

''MediaElements'' can be connected with method <code>connect()</code>. This method creates a directional connection between elements ''source'' and ''sink'' provided as parameters. All output streams of the ''source'' element are connected to the input streams of the ''sink'' element.

<pre>
public void connectElements() {
	MediaPipeline mp = mpf.create();

	HttpGetEndpoint httpEndpoint = mp.newHttpGetEndpoint()
		.terminateOnEOS().build();
	PlayerEndpoint player = mp.newPlayerEndpoint("file:///myfile.avi")
		.build();
		
	player.connect(httpEndpoint);
		
}
</pre>
 
In order to create bidirectional connections the application must perform a connect operation in both directions.

<pre>
public void back2back () {
	MediaPipeline mp = mpf.create();
	
	RtpEndpoint rtpA = mp.newRtpEndpoint().build();
	RtpEndpoint rtpB = mp.newRtpEndpoint().build();
		
	rtpA.connect(rtpB);
	rtpB.connect(rtpA);
}
</pre>

Notice that method <code>connect()</code> won't do anything when elements without input streams, like <code>PlayerEndpoint</code> are passed as ''sink'' or elements with no output streams, like <code>RecorderEndpoint</code>, are passed as ''source''.

The ''Media API'' provides an asynchronous interface for those applications that cannot afford to block their calls until ''KMS'' responds. The asynchronous interface improves performance at a cost of increase in complexity.

<pre>
private MediaPipeline mp;
	
public void buildAsync () {
	mp = mpf.create();
	mp.newHttpGetEndpoint().buildAsync( new Continuation<HttpGetEndpoint>() {
		@Override
		public void onSuccess(HttpGetEndpoint result) {
			connectAsync (null, result);
		}
		@Override
		public void onError(Throwable cause) {
			// log error
		}
	});
		
	mp.newPlayerEndpoint("file:///myfile.webm").buildAsync( new
		Continuation<PlayerEndpoint>() {
		@Override
		public void onSuccess(PlayerEndpoint result) {
			connectAsync (result, null);
		}
		@Override
		public void onError(Throwable cause) {
			// log error
		}
	});
}
	
private HttpGetEndpoint http;
private PlayerEndpoint player;

public void connectAsync(PlayerEndpoint player, HttpGetEndpoint http) {
	if (player != null) {
		this.player = player;
	}
	if ( http != null) {
		this.http = http;
	}
	if (player != null && http != null){
		player.connect(http);
	}
}
</pre>

==== HttpGetEndpoint ====

An ''HttpGetEndpoint'' contains source ''Media Pads'' for audio and video, delivering media using HTML5 pseudo-streaming mechanism. This type of  endpoint provide unidirectional communications. Its ''Media Sink'' is associated with the HTTP GET method.

A ''Media Pad'' is an element´s interface with the outside world. The data streams flow from the ''Media Source'' pad to another element's ''Media Sink'' pad.

==== HttpPostEndpoint ====

An ''HttpPostEndpoint'' contains sink pads for audio and video, which provide access to an HTTP file upload function This type of endpoint provide unidirectional communications. Its ''Media Sources'' are accessed through the HTTP POST method.

==== PlayerEndpoint ====

A ''PlayerEndpoint'' retrieves content from seekable sources in reliable mode (does not discard media information) and inject them into KMS. It contains one ''Media Source'' for each media type detected.

==== RecorderEndpoint ====

A ''RecorderEndpoint''  provides function to store contents in reliable mode (doesn't discard data). It contains ''Media Sink'' pads for audio and video.

==== RtpEndpoint ====

A ''RtpEndpoint'' provides bidirectional content delivery capabilities with remote networked peers through RTP protocol. It contains paired sink and source ''Media Padsource '' for audio and video.

==== WebRtcEndpoint ====

A ''WebRtcEndpoint'' provide media streaming for Real Time Communications (RTC) through the web.

=== Filters ===

Filters perform media processing, computer vision, augmented reality, and so on.

==== JackVaderFilter ====

JackVaderFilter detects faces in a video feed. Those on the right half of the feed are overlaid with a pirate hat, and those on the left half are covered by a Darth Vader helmet. This is an example filter, intended to demonstrate how to integrate computer vision capabilities into the KMS multimedia infrastructure.

<pre>
JackVaderFilter filter = mediaPipeline.newJackVaderFilter().build();
</pre>

==== ZBarFilter ====

This filter detects QR and bar codes in a video feed. When a code is found, the filter raises a {@link CodeFoundEvent}. Clients can add a listener to this event using the method.

<pre>
ZBarFilter zBarFilter = mediaPipeline.newZBarFilter().build();
zBarFilter.addCodeFoundDataListener(new MediaEventListener<CodeFoundEvent>() {
	@Override
	public void onEvent(CodeFoundEvent event) {
		log.info("Code Found " + event.getValue());
		// ...
	});
}
</pre>

==== FaceOverlayFilter ====

This type of filter detects faces in a video feed. The face is then overlaid with an image.

<pre>
MediaPipeline mp = session.getMediaPipelineFactory().create();
FaceOverlayFilter faceOverlayFilter = mp.newFaceOverlayFilter().build();
// xoffset%, y offset%, width%, height%
faceOverlayFilter.setOverlayedImage("/img/masks/mario-wings.png", -0.35F, -1.2F, 1.6F, 1.6F);
</pre>

==== PointerDetectorFilter and PointerDetectorAdvFilter ====

These type of filters detects pointers in a video feed. The difference is in the way of calibration of such pointers.

<pre>
PointerDetectorWindowMediaParam start = new PointerDetectorWindowMediaParamBuilder(
				"start", 100, 100, 280, 380).withImage(
				"/img/buttons/start.png").build();
PointerDetectorAdvFilter pointerDetectorAdvFilter = mediaPipeline
				.newPointerDetectorAdvFilter(new WindowParam(5, 5, 50, 50))
				.withWindow(start).build();
</pre>

==== GStreamerFilter ====

This is a generic filter interface, that creates GStreamer filters in the media server.

<pre>
GStreamerFilter mirrorFilter = mediaPipeline.newGStreamerFilter("videoflip method=4")
				.build();
</pre>

==== ChromaFilter ====

This type of filter makes transparent a colour range in the top layer, revealing another image behind.

<pre>
ChromaFilter chromaFilter = mediaPipeline.newChromaFilter(
				new WindowParam(100, 10, 500, 400)).build();
</pre>

==== CrowdDetectorFilter ====

This type of filter detects people agglomeration in video streams.

<pre>
List<Point> points = new ArrayList<Point>();
points.add(new Point(0, 0));
points.add(new Point(640, 0));
points.add(new Point(640, 480));
points.add(new Point(0, 480));
RegionOfInterestConfig config = new RegionOfInterestConfig();
config.setFluidityLevelMin(10);
config.setFluidityLevelMed(35);
config.setFluidityLevelMax(65);
config.setFluidityNumFramesToEvent(5);
config.setOccupancyLevelMin(10);
config.setOccupancyLevelMed(35);
config.setOccupancyLevelMax(65);
config.setOccupancyNumFramesToEvent(5);
config.setSendOpticalFlowEvent(false);
List<RegionOfInterest> rois = newArrayList(new RegionOfInterest(
		points, config, "Roi"));
CrowdDetectorFilter crowdDetector = mp.newCrowdDetectorFilter(
		rois).build();
playerEndpoint.connect(crowdDetector);
</pre>

==== PlateDetectorFilter ====

This filter detects vehicle plates in a video feed.

<pre>
PlateDetectorFilter plateDetectorFilter = mp
		.newPlateDetectorFilter().build();
plateDetectorFilter
		.addPlateDetectedListener(new MediaEventListener<PlateDetectedEvent>() {
			@Override
			public void onEvent(PlateDetectedEvent event) {
				session.publishEvent(new ContentEvent(event
					.getType(), event.getPlate()));
			}
		});
</pre>

=== Mixers ===

==== Dispatcher ====

A ''Dispatcher'' is a ''Hub'' that allows routing between arbitrary port pairs. The connections made by a ''Dispatcher'' is through Media Elements called ''HubPort'':

<pre>
Dispatcher dispatcher = mp.newDispatcher().build();
HubPort hubPort1 = dispatcher.newHubPort().build();
HubPort hubPort2 = dispatcher.newHubPort().build();
endpoint1.connect(hubPort1);
endpoint2.connect(hubPort2);
dispatcher.connect(hubPort1, hubPort2);
</pre>

==== DispatcherOneToMany ====

A ''DispatcherOneToMany'' is a ''Hub'' that sends a given source to all the connected sinks:

<pre>
Dispatcher dispatcherOneToMany = mediaPipeline.newDispatcherOneToMany().build();
HubPort hubPort1 = dispatcherOneToMany.newHubPort().build();
endpoint1.connect(hubPort1);
dispatcherOneToMany.setSource(hubPort1);
</pre>

==== Composite ====

A ''Composite'' is a ''Hub'' that mixes the audio stream of its connected sources and constructs a grid with the video streams of its connected sources into its sink:

<pre>
Composite composite = mediaPipeline.newComposite().build();
HubPort hubPort = composite.newHubPort().build();
endpoint.connect(hubPort);
</pre>

== Programming with the Stream Oriented GE HTML5 SDK ==

The ''Stream Oriented GE HTML5'' SDK is a ''Javascript'' library implementing a ''Content API'' and a ''Media API'' client. The following sections provides details about these SDK libraries.

=== KWS Content API ===

It has been designed to be compatible with ''node.js'' infrastructure and all its dependencies have been included into the ''Node Package Modules'' (''NPM''). For that reason it is required the ''NPM'' dependency management infrastructure to be installed.

<pre>
sudo apt-get install npm
</pre>

Current release of HTML5 SDK does not provide a library archive, so it must be built directly from the [https://github.com/Kurento/kws-content-api source code]. A [https://forge.fi-ware.eu/frs/download.php/818/kws-content-api.min.js bundle file] is also available at FI-WARE download page.

<pre>
git clone https://github.com/Kurento/kws-content-api.git
cd kws-content-api
npm install
npm update
node_modules/.bin/grunt
</pre>

''Grunt'' will place into directory <code>dist</code> four different ''Javascript'' bundles adapted to browser usage. 

If you are developing your application with maven, simply add the Kurento Content Management API for Web SDK library (<code>kws-content-api.js</code>) as a regular dependency:

<pre>
<dependencies>
    ...
    <dependency>
        <groupId>com.kurento.kmf</groupId>
        <artifactId>kws-content-api</artifactId>
        <version>4.2.2</version>
    </dependency>
    ...
</dependencies>
</pre>

This way, <code>kws-content-api.js</code> will be available in your web application root, as follows:

<pre>
<html>
     <head>
	 <script src=”./kws-content-api.js”/>
     </head>
     <body>
	 …
     </body>
</html>
</pre>

In order to use the ''Stream Oriented GE HTML5'' SDK the ''Content API'' must activate the control protocol at handler level. Boolean attribute <code>useControlProtocol</code> is used for this purpose.

<pre>
@HttpPlayerService(path = "/myPlayerService" , useControlProtocol=true)
public class MyPlayerService extends HttpPlayerHandler {

	@Override
	public void onContentRequest(HttpPlayerSession contentSession) throws Exception {
		// Handler actions
	}

</pre>

The ''Stream Oriented GE HTML5'' SDK provides the following set of ''Content API'' clients:

* '''''KwsContentPlayer''''':  Allows connection with Kurento's ''HTTP player handler'' in order to implement download services.
*'''''KwsContentUploader''''': Intended to interoperate with the ''HTTP recorder handler''. It allows implementing file upload services.
*'''''KwsWebRtcContent''''': Helps applications to setup WebRTC connections with the ''WebRTC handler''.

Clients above are intended to connect one ''Content API service''. The constructor must provide the URL of the ''service entry point''.

<pre>
<script>
function play(){
        var KwsContentPlayer = kwsContentApi.KwsContentPlayer;
        conn = new KwsContentPlayer("http://myServer/myApp/myPlayerService", options);
}
</script>
</pre>

Optional parameters can be provided with configurations customized to the service.

* ''''audio'''': Sets the audio stream mode. Can be any of <code>inactive</code>, <code>sendonly</code>, <code>recvonly</code> and <code>sendrecv</code>. Default value is <code>sendrecv</code>.
* '''''video''''': Sets the video stream mode with the same alternatives available to audio. Default value is <code>sendrecv</code>.
* '''''localVideoTag''''': ID of the <code><video></code> tag where local video will be displayed. No local video will be displayed if not defined.
* '''''remoteVideoTag''''': ID of the <code><video></code> tag where remote video will be displayed. No remote video will be displayed if not defined.
* '''''iceServers''''': ''STUN/TURN'' server array used by ''WebRTC ICE'' client. By default ''Google'' public ''STUN'' server is used.

Upon creation the client sends a start request to the server, causing the method <code>onContentRequest()</code> to be called in the service handler.

The same ''content session'' events received in the ''service handler'' are also available on the client side. Listeners are provided for this purpose. 

<pre>
<html>
    <script>
	var uri = "http://www.example.com/jsonrpc";

	var options =
	{
 	     localVideoTag:  'localVideo',
 	     remoteVideoTag: 'remoteVideo'
	};

	var conn = new KwsWebRtcContent(uri, options);

	// Start and terminate events
	conn.on('start', function()
	{
  	    console.log("Connection started");
	});
	conn.on('terminate', function(reason)
	{
  	    console.log("Connection terminated due to "+reason.message);
	});

	// LocalStream and remoteStream events
	conn.on('localstream', function(data)
	{
  	    console.info("LocalStream set to "+data.url);
	});
	conn.on('remotestream', function(data)
	{
  	    console.info("RemoteStream set to "+data.url);
	});

	// Media event
	conn.on('mediaevent', function(data)
	{
  	    console.info("MediaEvent: "+JSON.stringify(data));
	});

	// Error
	conn.on('error', function(error)
	{
  	    console.error(error.message);
	});
    </script>
    <body>
	<video id=”localVideo”/>
	<video id=”remoteVideo”/>
    </body>
</html>
</pre>

=== KWS Media API ===

KWS Media API provides the capabilities to create Media Pipelines and Media Elements in the KMS without a KAS. In other words, with KWS Media API we can create Kurento-based applications directly in JavaScript.

To describe this API, we are going to show how to create a basic pipeline that play a video file from its URL and stream it over HTTP. You can also download and check this [https://github.com/Kurento/kws-media-api/tree/develop/example/PlayerEndpoint-HttpGetEndpoint example full source code.

<ol>
<li>Create an instance of the KwsMedia class that will manage the connection with the Kurento Media Server, so you'll need to provide the URI of its WebSocket endpoint. Alternatively, instead of using a constructor, you can also provide success and error callbacks:
<pre>
   var kwsMedia = kwsMediaApi.KwsMedia(ws_uri);
   
   kwsMedia.onconnect = function(kwsMedia)
   {
     …
   };
   kwsMedia.onerror = function(error)
   {
     …
   };
</pre>
<pre>
   kwsMediaApi.KwsMedia(ws_uri, function(kwsMedia)
   {
     …
   },
   function(error)
   {
     …
   });
</pre>
</li>
<li>Create a pipeline. This will host and connect the diferent elements. In case of error, it will be notified on the ```error``` parameter of the callback, otherwise this will be null as it's common on Node.js style APIs:
<pre>
   kwsMedia.createMediaPipeline(function(error, pipeline)
   {
     …
   });
</pre>
</li>
<li>Create the elements. The player need an object with the URL of the video, and and we'll also subscribe to the 'EndOfStream' event of the HTTP stream:
<pre>
   PlayerEndpoint.create(pipeline,
   {uri: "https://ci.kurento.com/video/small.webm"},
   function(error, player)
   {
     …
   });

   HttpGetEndpoint.create(pipeline, function(error, httpGet)
   {
     httpGet.on('EndOfStream', function(event)
     {
       …
     });

     …
   });
</pre>
</li>
<li>Connect the elements, so the media stream can flow between them:
<pre>
   pipeline.connect(player, httpGet, function(error, pipeline)
   {
     …
   });
</pre>
</li>
<li>Get the URL where the media stream will be available:
<pre>
   httpGet.getUrl(function(error, url)
   {
     …
   });
</pre>
</li>
<li>Start the reproduction of the media:
<pre>
   player.play(function(error)
   {
     …
   });
</pre>
</li>
</ol>

== Examples ==

This section provides several examples of the ''Stream Oriented GE Kurento'' platform. To that aim we are going to use the Java Content and Media API in the server-side, and the JavaScript Content API in the client-side. The provided examples implement a ''MediaPipeline'' composed by a ''PlayerEndpoint'' connected to a ''Filter'' and generating a media flow through an ''HttpGetEndpoint''. The main difference between these two example is the filter. The first example uses the ''JackVaderFilter''. This filter is an example of augmented reality element, since it  recognizes faces in media streams adding Jack Sparrow or Darth Vader hat onto these faces.The second example uses the ''ZBarFilter''. This filter is an example of computational vision element, since it recognize bar and QR codes in a media stream generating events with the information of the detected codes in the stream. Therefore, the ''MediaPipelines'' used in these examples are the following:

* ''PlayerEndpoint'' &rarr; ''JackVaderFilter'' &rarr; ''HttpGetEndpoint''
* ''PlayerEndpoint'' &rarr; ''ZBarFilter'' &rarr; ''HttpGetEndpoint''

For both examples, the handler (Java) and client (JavaScript) code is provided.

===JackVaderFilter===

The handler code (Java) for this example is shown in the snippet below. This handler is deployed in the KAS at the path <code>http://myserver/myApp/playerJsonJackVader</code>. The ''PlayerEndpoint'' uses an URL to locate a media stream (https://ci.kurento.com/video/fiwarecut.webm) and then ''JackVaderFilter'' puts a pirate hat in the faces of this video. 

<pre>
//This annotation configures the platform to deploy a handler on the specified path
@HttpPlayerService(path = "/playerJsonJackVader")
public class PlayerJsonJackVaderFilter extends HttpPlayerHandler {

	@Override
	public void onContentRequest(HttpPlayerSession session) throws Exception {
		MediaPipelineFactory mpf = session.getMediaPipelineFactory();
		MediaPipeline mp = mpf.create();

		//This makes the pipeline (and all its elements) to be released when the session terminates
		session.releaseOnTerminate(mp);

		//Create a PlayerEndpoint for injecting a video into the platform
		PlayerEndpoint playerEndpoint = mp.newPlayerEndpoint(
				"https://ci.kurento.com/video/fiwarecut.webm").build();

		//Create a filter for augmenting the video stream in real time.
		JackVaderFilter filter = mp.newJackVaderFilter().build();

		//Connect both elements
		playerEndpoint.connect(filter);

		//Store a player reference for later use
		session.setAttribute("player", playerEndpoint);

		//Create a HttpGetEndpoint and connects it to the filter
		HttpGetEndpoint httpEndpoint = mp.newHttpGetEndpoint()
				.terminateOnEOS().build();
		filter.connect(httpEndpoint);
		
		//Start session
		session.start(httpEndpoint);
	}

	@Override
	public void onContentStarted(HttpPlayerSession session) {
		//Content starts when the client connects to the HttpEndpoin
		//At that instant, the player must start reproducing the file
		PlayerEndpoint playerEndpoint = (PlayerEndpoint) session
				.getAttribute("player");
		playerEndpoint.play();
	}

}
</pre>

In order to perform a request to this handler, we create a simple HTML page in which the JavaScript Content API library (i.e. ''kws-content-api.js'') is used. Depending on your development methodoloy, you may need to dowload that library to the appropriate directoy. This HTML page must be included in the same WAR than the handler. Thus, in order to locate the handler path the JavaScript object <code>document.URL</code> is used:

<pre>
<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>Stream Oriented GE Kurento</title>
<script src="./kws-content-api.js"></script>
<script>
	var conn;

	function start() {
		// Handler
		var handler = document.getElementById("handler").value;

		// Options
		var options = {
			remoteVideoTag: "remoteVideo"
		};

		// KwsContentPlayer instantiation
		var KwsContentPlayer = kwsContentApi.KwsContentPlayer;
		conn = new KwsContentPlayer(handler, options);

		// Media events log
		conn.on("mediaevent", function(data) {
			document.getElementById("events").value += JSON.stringify(data) + "\n";
		});
	}
	
	function stop() {
		conn.terminate();
	}
</script>
</head>

<body>
	<h1>Stream Oriented GE Kurento Examples</h1>

	<label for="selectFilter">Handler</label>
	<select id="handler">
		<option value="./playerJsonJackVader">JackVaderFilter</option>
		<option value="./playerJsonZBar">ZBarFilter</option>
	</select>
	<br />

	<label for="status">Events</label>
	<textarea id="events"></textarea>
	<br />

	<button id="start" onclick="start()">Start</button>
	<button id="stop" onclick="stop()">Stop</button>
	<br />

	<video id="remoteVideo" autoplay></video>
</body>
</html>
</pre>

All in all, to run this example we have to make a request using a browser to hte URL of this HTML page (e.g. <code>http://myserver/myApp/mypage.html</code>), select the ''JackVaderFilter'' option and finally press the ''Start'' button. As a result, the stream played is the video located in the URL determined in the handler (https://ci.kurento.com/video/fiwarecut.webm) but showing the speaker of the video with a pirate hut in his head. Notice that this example is providing the media in WebM format, so it will only work on browsers supporting it (e.g. Chrome and Firefox).

===ZBarFilter===

The handler code (Java) for this example is shown below. This handler is deployed in the KAS at the path <code>http://myserver/myApp/playerJsonZBar</code>. The ''PlayerEndpoint'' uses an URL to locate a media stream (https://ci.kurento.com/video/barcodes.webm) and then ''ZBarFilter'' generates media events with the detected codes within the video.

<pre>
@HttpPlayerService(path = "/playerJsonZBar")
public class PlayerJsonZBarFilter extends HttpPlayerHandler {

	@Override
	public void onContentRequest(final HttpPlayerSession session)
			throws Exception {
		MediaPipelineFactory mpf = session.getMediaPipelineFactory();
		MediaPipeline mp = mpf.create();
		PlayerEndpoint player = mp.newPlayerEndpoint(
				"https://ci.kurento.com/video/barcodes.webm").build();
		session.setAttribute("player", player);
		ZBarFilter zBarFilter = mp.newZBarFilter().build();
		player.connect(zBarFilter);
		HttpGetEndpoint httpEndpoint = mp.newHttpGetEndpoint()
				.terminateOnEOS().build();
		zBarFilter.connect(httpEndpoint);
		session.start(httpEndpoint);
		zBarFilter
				.addCodeFoundDataListener(new MediaEventListener<CodeFoundEvent>() {
					@Override
					public void onEvent(CodeFoundEvent event) {
						session.publishEvent(new ContentEvent(event.getType(),
								event.getValue()));
					}
				});

	}

	@Override
	public void onContentStarted(HttpPlayerSession session) {
		PlayerEndpoint playerEndpoint = (PlayerEndpoint) session
				.getAttribute("player");
		playerEndpoint.play();
	}

}
</pre>

To visualize the result of this handler, we use the same JavaScript code included in the previous example. This time, we select the ''ZBarFilter'' in the combo box and then press the ''Start'' button. As a result, the video containing QR codes is played (https://ci.kurento.com/video/barcodes.webm) and the detected codes by the filter are written in the HTML textarea with id ''events''.

Both ''JackVaderFilter'' and ''ZBarFilter'' examples can be developed as a Maven project, and the resulting WAR is deployed in the KAS. An example of <code>pom.xml</code> for this Maven project in shown below.

<pre>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
   xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">

   <modelVersion>4.0.0</modelVersion>
   <groupId>com.kurento.kmf</groupId>
   <artifactId>kmf-content-helloworld</artifactId>
   <version>1.0.0</version>
   <packaging>war</packaging>

   <properties>
      <project.build.sourceEncoding>UTF-8 </project.build.sourceEncoding>
      <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>
      <maven.compiler.source>1.6</maven.compiler.source>
      <maven.compiler.target>1.6</maven.compiler.target>

      <!-- Kurento Dependencies Versions -->
      <kmf-content-api.version>4.2.2</kmf-content-api.version>
      <kws-content-api.version>4.2.2</kws-content-api.version>

      <!-- Plugins Versions -->
      <maven-war-plugin.version>2.3</maven-war-plugin.version>
   </properties>

   <dependencies>
      <dependency>
         <groupId>com.kurento.kmf</groupId>
         <artifactId>kmf-content-api</artifactId>
         <version>${kmf-content-api.version}</version>
      </dependency>
      <dependency>
         <groupId>com.kurento.kmf</groupId>
         <artifactId>kws-content-api</artifactId>
         <version>${kws-content-api.version}</version>
      </dependency>
   </dependencies>

   <build>
      <plugins>
         <plugin>
            <groupId>org.apache.maven.plugins</groupId>
            <artifactId>maven-war-plugin</artifactId>
            <version>${maven-war-plugin.version}</version>
         </plugin>
      </plugins>
   </build>

</project>
</pre>

The examples before and many others are available on [https://github.com/Kurento/kmf-content-demo GitHub]:

<pre>
git clone https://github.com/Kurento/kmf-content-demo.git
</pre>

